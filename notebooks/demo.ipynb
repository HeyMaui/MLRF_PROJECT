{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo notebook\n",
    "\n",
    "A quick presentation of what is possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10_classifier.classifier import Classifier\n",
    "from cifar10_classifier.config import Config\n",
    "from cifar10_classifier.data_getter import DataGetter\n",
    "from cifar10_classifier.feature_extractor import FeatureExtractor\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root_notebooks = os.getcwd()\n",
    "\n",
    "conf = Config(project_root_notebooks)\n",
    "data_getter = DataGetter(conf)\n",
    "feature_extractor_HOG = FeatureExtractor('HOG')\n",
    "feature_extractor_SIFT = FeatureExtractor('SIFT')\n",
    "feature_extractor_flatten = FeatureExtractor('flatten')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_getter.load_external_data()\n",
    "data_getter.save_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOG done\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_HOG.extract(data_getter.train_data, data_getter.train_labels, train=True)\n",
    "feature_extractor_HOG.extract(data_getter.test_data, data_getter.test_labels, train=False)\n",
    "print('HOG done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT done\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_SIFT.extract(data_getter.train_data, data_getter.train_labels, train=True)\n",
    "feature_extractor_SIFT.extract(data_getter.test_data, data_getter.test_labels, train=False)\n",
    "print('SIFT done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten done\n"
     ]
    }
   ],
   "source": [
    "feature_extractor_flatten.extract(data_getter.train_data, data_getter.train_labels, train=True)\n",
    "feature_extractor_flatten.extract(data_getter.test_data, data_getter.test_labels, train=False)\n",
    "print('flatten done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = SVC()\n",
    "clf_LogReg = LogisticRegression(max_iter=10000)\n",
    "clf_RandomForest = RandomForestClassifier()\n",
    "\n",
    "clf_SVC=Classifier(clf_SVC)\n",
    "clf_LogReg=Classifier(clf_LogReg)\n",
    "clf_RandomForest=Classifier(clf_RandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVC on HOG feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC.fit_classifier(feature_extractor_HOG.train_descriptors, data_getter.train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LogisticRegression on HOG feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LogReg.fit_classifier(feature_extractor_HOG.train_descriptors, data_getter.train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RandomForest on HOG feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RandomForest.fit_classifier(feature_extractor_HOG.train_descriptors, data_getter.train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing HOG Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOG_models = [copy.deepcopy(clf_SVC), copy.deepcopy(clf_LogReg), copy.deepcopy(clf_RandomForest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = SVC()\n",
    "clf_LogReg = LogisticRegression(max_iter=10000)\n",
    "clf_RandomForest = RandomForestClassifier()\n",
    "\n",
    "clf_SVC=Classifier(clf_SVC)\n",
    "clf_LogReg=Classifier(clf_LogReg)\n",
    "clf_RandomForest=Classifier(clf_RandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVC on SIFT feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC.fit_classifier(feature_extractor_SIFT.train_descriptors, data_getter.train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LogisticRegression on SIFT feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LogReg.fit_classifier(feature_extractor_SIFT.train_descriptors, data_getter.train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RandomForest on SIFT feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RandomForest.fit_classifier(feature_extractor_SIFT.train_descriptors, data_getter.train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing SIFT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIFT_models = [copy.deepcopy(clf_SVC), copy.deepcopy(clf_LogReg), copy.deepcopy(clf_RandomForest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC = SVC()\n",
    "clf_LogReg = LogisticRegression(max_iter=10000)\n",
    "clf_RandomForest = RandomForestClassifier()\n",
    "\n",
    "clf_SVC=Classifier(clf_SVC)\n",
    "clf_LogReg=Classifier(clf_LogReg)\n",
    "clf_RandomForest=Classifier(clf_RandomForest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVC on flatten feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_SVC.fit_classifier(feature_extractor_flatten.train_descriptors, data_getter.train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LogisticRegression on flatten feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_LogReg.fit_classifier(feature_extractor_flatten.train_descriptors, data_getter.train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training RandomForest on flatten feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RandomForest.fit_classifier(feature_extractor_flatten.train_descriptors, data_getter.train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing flatten models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_models = [copy.deepcopy(clf_SVC), copy.deepcopy(clf_LogReg), copy.deepcopy(clf_RandomForest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "0.6419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68      1000\n",
      "           1       0.77      0.78      0.78      1000\n",
      "           2       0.54      0.49      0.52      1000\n",
      "           3       0.48      0.45      0.46      1000\n",
      "           4       0.55      0.61      0.58      1000\n",
      "           5       0.52      0.51      0.52      1000\n",
      "           6       0.69      0.73      0.71      1000\n",
      "           7       0.72      0.68      0.70      1000\n",
      "           8       0.72      0.71      0.72      1000\n",
      "           9       0.75      0.74      0.75      1000\n",
      "\n",
      "    accuracy                           0.64     10000\n",
      "   macro avg       0.64      0.64      0.64     10000\n",
      "weighted avg       0.64      0.64      0.64     10000\n",
      "\n",
      "LogReg\n",
      "0.531\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.59      0.60      1000\n",
      "           1       0.61      0.63      0.62      1000\n",
      "           2       0.45      0.41      0.43      1000\n",
      "           3       0.41      0.32      0.36      1000\n",
      "           4       0.45      0.49      0.47      1000\n",
      "           5       0.45      0.42      0.43      1000\n",
      "           6       0.52      0.64      0.57      1000\n",
      "           7       0.56      0.57      0.57      1000\n",
      "           8       0.59      0.58      0.59      1000\n",
      "           9       0.63      0.66      0.64      1000\n",
      "\n",
      "    accuracy                           0.53     10000\n",
      "   macro avg       0.53      0.53      0.53     10000\n",
      "weighted avg       0.53      0.53      0.53     10000\n",
      "\n",
      "RandomForest\n",
      "0.524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.62      1000\n",
      "           1       0.60      0.70      0.65      1000\n",
      "           2       0.43      0.35      0.39      1000\n",
      "           3       0.36      0.26      0.30      1000\n",
      "           4       0.46      0.47      0.46      1000\n",
      "           5       0.41      0.45      0.43      1000\n",
      "           6       0.52      0.65      0.58      1000\n",
      "           7       0.60      0.53      0.56      1000\n",
      "           8       0.61      0.59      0.60      1000\n",
      "           9       0.60      0.62      0.61      1000\n",
      "\n",
      "    accuracy                           0.52     10000\n",
      "   macro avg       0.52      0.52      0.52     10000\n",
      "weighted avg       0.52      0.52      0.52     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model, name in zip(HOG_models, ['SVC', 'LogReg', 'RandomForest']):\n",
    "    print(name)\n",
    "    y_pred = model.predict(feature_extractor_HOG.test_descriptors)\n",
    "    print(accuracy_score(data_getter.test_labels, y_pred))\n",
    "    print(classification_report(data_getter.test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model, name in zip(SIFT_models, ['SVC', 'LogReg', 'RandomForest']):\n",
    "    print(model)\n",
    "    y_pred = model.predict(feature_extractor_SIFT.test_descriptors)\n",
    "    print(accuracy_score(data_getter.test_labels, y_pred))\n",
    "    print(classification_report(data_getter.test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cifar10_classifier.classifier.Classifier object at 0x7fa285939cf0>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 3072 features, but SVC is expecting 288 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(flatten_models, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSVC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogReg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[0;32m----> 3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_extractor_flatten\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_descriptors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(accuracy_score(data_getter\u001b[38;5;241m.\u001b[39mtest_labels, y_pred))\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(classification_report(data_getter\u001b[38;5;241m.\u001b[39mtest_labels, y_pred))\n",
      "File \u001b[0;32m~/Epita/.venv/lib/python3.10/site-packages/cifar10_classifier/classifier.py:49\u001b[0m, in \u001b[0;36mClassifier.predict\u001b[0;34m(self, test_descriptors)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo model found, please provide a model from sklearn\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_descriptors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Epita/.venv/lib/python3.10/site-packages/sklearn/svm/_base.py:814\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    812\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[0;32m~/Epita/.venv/lib/python3.10/site-packages/sklearn/svm/_base.py:429\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    414\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform regression on samples in X.\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 429\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_for_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[0;32m~/Epita/.venv/lib/python3.10/site-packages/sklearn/svm/_base.py:607\u001b[0m, in \u001b[0;36mBaseLibSVM._validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    604\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel):\n\u001b[0;32m--> 607\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sp\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m    617\u001b[0m     X \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix(X)\n",
      "File \u001b[0;32m~/Epita/.venv/lib/python3.10/site-packages/sklearn/base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Epita/.venv/lib/python3.10/site-packages/sklearn/base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 3072 features, but SVC is expecting 288 features as input."
     ]
    }
   ],
   "source": [
    "for model, name in zip(flatten_models, ['SVC', 'LogReg', 'RandomForest']):\n",
    "    print(model)\n",
    "    y_pred = model.predict(feature_extractor_flatten.test_descriptors)\n",
    "    print(accuracy_score(data_getter.test_labels, y_pred))\n",
    "    print(classification_report(data_getter.test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting some graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot roc curves of every model on same graph for \n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "def plot_roc_curve(models, features, labels):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
